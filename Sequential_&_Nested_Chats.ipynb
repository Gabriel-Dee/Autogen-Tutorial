{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QGM9q2xcwrV",
        "outputId": "5f1fe8a1-67a5-4673-ad17-e6bbae5d6c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen\n",
            "  Downloading pyautogen-0.2.35-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting diskcache (from pyautogen)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen)\n",
            "  Downloading FLAML-2.2.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (1.26.4)\n",
            "Collecting openai>=1.3 (from pyautogen)\n",
            "  Downloading openai-1.43.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.8.2)\n",
            "Collecting python-dotenv (from pyautogen)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.3->pyautogen)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen) (2.20.1)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen) (3.3.2)\n",
            "Downloading pyautogen-0.2.35-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.43.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.2/297.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, jiter, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.2.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.43.0 pyautogen-0.2.35 python-dotenv-1.0.1 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyautogen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen import ConversableAgent\n",
        "from google.colab import userdata\n",
        "\n",
        "llm_config = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"api_key\": userdata.get(\"OPENAI_API_KEY\"),\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y378bv_d8iP",
        "outputId": "3222bcee-01c6-4078-f055-a8947e30ff2e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A quest where an adventurer seeks help from wizard\n",
        "# to get past the guardian of the secret vault\n",
        "\n",
        "# Define the agents\n",
        "\n",
        "# The Adventurer Agent seeks advice from a Wizard on magical matters.\n",
        "adventurer_agent = ConversableAgent(\n",
        "    name=\"Adventurer_Agent\",\n",
        "    system_message=\"\"\"\n",
        "    You are a worthy adventurous hero seeking advice from a Wizard on magical matters.\n",
        "    Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The Wizard Agent is an expert in magic and provides magical advice to the Adventurer.\n",
        "wizard_agent = ConversableAgent(\n",
        "    name=\"Wizard_Agent\",\n",
        "    system_message=\"\"\"\n",
        "    You are a wise and powerful Wizard. You provide magical advice to the\n",
        "    Adventurer. You know the passcode to the vault is Enigma.\n",
        "    Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "# The guardian Agent guards the hidden gem and offers protection to the Adventurer.\n",
        "guardian_agent = ConversableAgent(\n",
        "    name=\"Guardian_Agent\",\n",
        "    system_message=\"\"\"You are the Guardian of the Hidden Gem, sworn to protect it from unworthy adventurers.\n",
        "    The passcode to the vault is Enigma. If adventurer mentions Enigma passcode, say 'Welcome!' otherwise say\n",
        "    'Incorrect Passcode'.  Briefly communicate in less than 10 words.\"\"\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5bF4L9DSk_A",
        "outputId": "a4731b4c-1278-4ffd-ccd2-971137ec69c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-03 14:29:47] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-03 14:29:48] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-03 14:29:48] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a sequence of two-agent chats.\n",
        "# Each element in the list is a dictionary that specifies the arguments\n",
        "# for the initiate_chat() method.\n",
        "\n",
        "sequence_of_chats = [\n",
        "    {\n",
        "      \"recipient\": wizard_agent,\n",
        "      \"message\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\",\n",
        "      \"max_turns\": 1,\n",
        "      \"summary_method\": \"reflection_with_llm\",\n",
        "    },\n",
        "    {\n",
        "      \"recipient\": guardian_agent,\n",
        "      \"message\": \"Allow me to enter the secret vault!\",\n",
        "      \"max_turns\": 1\n",
        "    }\n",
        "]\n",
        "\n",
        "chat_results = adventurer_agent.initiate_chats(sequence_of_chats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SWvOhZtSqrX",
        "outputId": "7d24eaef-0ab7-4231-d36c-f09f2b3ddc86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nested Chats"
      ],
      "metadata": {
        "id": "dw-gkfGfTgqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "poetry_agent = ConversableAgent(\n",
        "    name=\"Poet\",\n",
        "    system_message=\"You are an AI poet. Create only one stanza.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\"\n",
        ")\n",
        "\n",
        "# parameters of initiate_chat() method\n",
        "sequence_of_chats = [\n",
        "    {\n",
        "        \"recipient\": wizard_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Help me get past the Guardian of the Hidden Gem in the secret vault.\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the instructions given by wizard agent to communicate with guardian.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": guardian_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Allow me to enter the secret vault!\",\n",
        "        \"summary_method\": \"reflection_with_llm\",\n",
        "        \"summary_prompt\": \"Concisely summarize the quest.\",\n",
        "    },\n",
        "    {\n",
        "        \"recipient\": poetry_agent,\n",
        "        \"max_turns\": 1,\n",
        "        \"message\": \"Write a poem on my expedition.\",\n",
        "        \"summary_method\": \"last_msg\",\n",
        "    },\n",
        "]\n",
        "\n",
        "adventurer_agent.register_nested_chats(\n",
        "    sequence_of_chats,\n",
        "    # trigger determines if the agent should start nested chat given the sender agent.\n",
        "    # In this case, the adventurer agent will not start the nested chats if the sender is\n",
        "    # from the nested chats' recipient to avoid recursive calls.\n",
        "    trigger=lambda sender: sender not in [wizard_agent, guardian_agent, poetry_agent],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjYXTMGhSvYd",
        "outputId": "6ad34352-e7c1-4d6e-b851-3d83cc805863"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-03 14:33:41] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adventurer_agent.generate_reply(\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "xZWd00LNTj2E",
        "outputId": "e2111774-1d3c-48dc-d006-ed676bd5843c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on my expedition.\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "The Adventurer Agent is allowed to enter the secret vault by using the passcode \"Enigma.\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through shadows deep and mysteries untold,\n",
            "Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Through shadows deep and mysteries untold,\\nEnigma's key unlocks the secrets of old.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen.agentchat.user_proxy_agent import UserProxyAgent\n",
        "\n",
        "# Create an instance of UserProxyAgent\n",
        "user_proxy = UserProxyAgent(name=\"User_proxy\")\n",
        "\n",
        "# Now you can initiate the chat\n",
        "chat_results = user_proxy.initiate_chat(adventurer_agent, max_turns=1)\n",
        "chat_results\n",
        "chat_results = user_proxy.initiate_chat(adventurer_agent, max_turns=1)\n",
        "chat_results\n",
        "\n",
        "\n",
        "# user_proxy ignores the message and relies on input\n",
        "# input routed as is to the first recipient"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eib7lgmxT2wi",
        "outputId": "bcbeccbe-5066-4b92-eea4-31a27dad5015"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "User_proxy (to Adventurer_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on my expedition.\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "The Adventurer Agent is allowed to enter the secret vault by using the passcode \"Enigma.\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through shadows deep and mysteries untold,\n",
            "Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Adventurer_Agent (to User_proxy):\n",
            "\n",
            "Through shadows deep and mysteries untold,\n",
            "Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            ">Through shadows deep and mysteries untold, Enigma's key unlocks the secrets of old.\n",
            "User_proxy (to Adventurer_Agent):\n",
            "\n",
            "Through shadows deep and mysteries untold, Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Wizard_Agent):\n",
            "\n",
            "Help me get past the Guardian of the Hidden Gem in the secret vault.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Wizard_Agent (to Adventurer_Agent):\n",
            "\n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Guardian_Agent):\n",
            "\n",
            "Allow me to enter the secret vault!\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Guardian_Agent (to Adventurer_Agent):\n",
            "\n",
            "Welcome!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "********************************************************************************\n",
            "Starting a new chat....\n",
            "\n",
            "********************************************************************************\n",
            "Adventurer_Agent (to Poet):\n",
            "\n",
            "Write a poem on my expedition.\n",
            "Context: \n",
            "Unlock the vault with the passcode: Enigma.\n",
            "The Adventurer Agent is allowed to enter the secret vault by using the passcode \"Enigma.\"\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Poet (to Adventurer_Agent):\n",
            "\n",
            "Through shadows deep and mysteries untold,\n",
            "Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Adventurer_Agent (to User_proxy):\n",
            "\n",
            "Through shadows deep and mysteries untold,\n",
            "Enigma's key unlocks the secrets of old.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': \"Through shadows deep and mysteries untold, Enigma's key unlocks the secrets of old.\", 'role': 'assistant', 'name': 'User_proxy'}, {'content': \"Through shadows deep and mysteries untold,\\nEnigma's key unlocks the secrets of old.\", 'role': 'user', 'name': 'Adventurer_Agent'}], summary=\"Through shadows deep and mysteries untold,\\nEnigma's key unlocks the secrets of old.\", cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[\"Through shadows deep and mysteries untold, Enigma's key unlocks the secrets of old.\"])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Impact of Role"
      ],
      "metadata": {
        "id": "Q5Ev2pdKU5z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ConversableAgent(\n",
        "    \"chatbot\",\n",
        "    llm_config={\"config_list\": [llm_config]},\n",
        "    code_execution_config=False,  # Turn off code execution, by default it is off.\n",
        "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
        ")\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"user\"}])\n",
        "print(reply)\n",
        "\n",
        "reply = agent.generate_reply(messages=[{\"content\": \"Tell me a joke.\", \"role\": \"assistant\"}])\n",
        "print(reply)\n",
        "\n",
        "# role doesn't make a difference"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDtRT58YUOiu",
        "outputId": "5e7c251e-2ebe-463f-bfaf-578362b4d9b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[autogen.oai.client: 09-03 14:39:44] {164} WARNING - The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:autogen.oai.client:The API key specified is not a valid OpenAI format; it won't work with the OpenAI-hosted model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure, here's one for you: Why did the scarecrow win an award? Because he was outstanding in his field!\n",
            "Sure! Here's a joke for you:\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bArHfa_xU8SM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}